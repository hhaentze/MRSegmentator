{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b50d85e5-309f-4111-bb51-9357f2b7766d",
   "metadata": {},
   "source": [
    "# Compare our model with nnUNet\n",
    "[nnUNet](https://github.com/MIC-DKFZ/nnUNet) requires that images have the same geometry  (same shape, spacing etc.). This is not the case for the UKBB data, where geometry differs between section. Hence, I will split the data sectionwise and train a new model for each section.\n",
    "\n",
    "The final models will most likely be patch-based and (hopefully) share similar parameters. Using those common parameters I will design a patch-based geometry-independent architecture that I can train on data from all sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13176a5a-f7c3-4252-ac00-b0244050247d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# private libraries\n",
    "import sys\n",
    "\n",
    "if \"../scripts\" not in sys.path:\n",
    "    sys.path.insert(1, \"../scripts\")\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d853f7-e8dc-4897-bddb-2994f04db153",
   "metadata": {},
   "source": [
    "## Prepare dataset folder structure\n",
    "A guide to the required folder structure can be found [here](https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/dataset_format.md).\n",
    "\n",
    "To avoid having multiple copies of the same files I will replicate the folder structure with soft links."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefafd94-423b-461c-abbc-d3938f3b0c8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Folders for Self-supervised Training on Presegmented Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8eb35a-d6ac-4810-8063-6b39158af775",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(config.ukbb + \"train.csv\")\n",
    "valid = pd.read_csv(config.ukbb + \"valid.csv\")\n",
    "data = pd.concat((train, valid)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8638128a-7eaf-4fa6-b7f7-aea47a05ee1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = config.ukbb_cache + \"nnUNet/nnUNet_raw/\"\n",
    "mkdir = lambda _dir: os.mkdir(_dir) if not os.path.exists(_dir) else None\n",
    "\n",
    "# create directories\n",
    "_dir = PATH + \"Dataset004_allSections\"\n",
    "mkdir(_dir)\n",
    "mkdir(_dir + \"/imagesTr\")\n",
    "mkdir(_dir + \"/labelsTr\")\n",
    "\n",
    "# link images and labels\n",
    "for i, row in data.reset_index().iterrows():\n",
    "    _id = str(i + 1).zfill(4)\n",
    "    # image\n",
    "    os.symlink(\n",
    "        src=config.ukbb + \"nifti/\" + row[\"image\"],\n",
    "        dst=_dir + \"/imagesTr/\" + f\"UKBB_{_id}_0000.nii.gz\",\n",
    "    )\n",
    "\n",
    "    # label\n",
    "    os.symlink(\n",
    "        src=config.ukbb + \"preds_combined2/\" + row[\"label\"],\n",
    "        dst=_dir + \"/labelsTr/\" + f\"UKBB_{_id}.nii.gz\",\n",
    "    )\n",
    "\n",
    "# dataset json\n",
    "dataset_json = {\n",
    "    \"channel_names\": {\"0\": \"MR\"},\n",
    "    \"labels\": {\"background\": 0} | {str(i): i for i in range(1, 41)},\n",
    "    \"numTraining\": len(data),\n",
    "    \"file_ending\": \".nii.gz\",\n",
    "}\n",
    "with open(_dir + \"/dataset.json\", \"w\") as f:\n",
    "    json.dump(dataset_json, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35366235-8375-486f-b66a-f865d3b6dd38",
   "metadata": {},
   "source": [
    "### Folders for Fine-tuning on Annotated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a067509-2f50-4989-bdfa-c5db166cc4ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = config.ukbb_cache + \"nnUNet/nnUNet_raw/\"\n",
    "mkdir = lambda _dir: os.mkdir(_dir) if not os.path.exists(_dir) else None\n",
    "\n",
    "# create directories\n",
    "_dir = PATH + \"Dataset005_finetuning\"\n",
    "mkdir(_dir)\n",
    "mkdir(_dir + \"/imagesTr\")\n",
    "mkdir(_dir + \"/labelsTr\")\n",
    "\n",
    "# link images and labels\n",
    "for i, row in data.reset_index().iterrows():\n",
    "    _id = str(i + 1).zfill(4)\n",
    "    # image\n",
    "    os.symlink(\n",
    "        src=row[\"image\"],\n",
    "        dst=_dir + \"/imagesTr/\" + f\"UKBB_{_id}_0000.nii.gz\",\n",
    "    )\n",
    "\n",
    "    # label\n",
    "    os.symlink(\n",
    "        src=row[\"label\"],\n",
    "        dst=_dir + \"/labelsTr/\" + f\"UKBB_{_id}.nii.gz\",\n",
    "    )\n",
    "\n",
    "# dataset json\n",
    "dataset_json = {\n",
    "    \"channel_names\": {\"0\": \"MR\"},\n",
    "    \"labels\": {\"background\": 0} | {str(i): i for i in range(1, 41)},\n",
    "    \"numTraining\": len(data),\n",
    "    \"file_ending\": \".nii.gz\",\n",
    "}\n",
    "with open(_dir + \"/dataset.json\", \"w\") as f:\n",
    "    json.dump(dataset_json, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd47918-99b4-40d9-8676-479e7c5818ee",
   "metadata": {},
   "source": [
    "## Execution Pipeline\n",
    "### 1. Create virtual environment\n",
    "```bash\n",
    "cd $HOME\n",
    "mamba create -n nnUNet python=3.11\n",
    "mamba activate nnUNet\n",
    "mamba  install pytorch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 pytorch-cuda=11.7 -c pytorch -c nvidia\n",
    ".conda/envs/nnUNet/bin/pip install nnunetv2\n",
    "```\n",
    "\n",
    "### 2. Export environment variables\n",
    "```bash\n",
    "export nnUnet_root=\"...\"\n",
    "export nnUNet_raw=\"$nnUnet_root/nnUNet_raw\"\n",
    "export nnUNet_preprocessed=\"$nnUnet_root/nnUNet_preprocessed\"\n",
    "export nnUNet_results=\"/$nnUnet_root/nnUNet_results\"\n",
    "```\n",
    "\n",
    "### 3. Fingerprint extraction, experiment planning and preprocessing\n",
    "```bash\n",
    "nnUNetv2_plan_and_preprocess -d 4 --verify_dataset_integrity\n",
    "```\n",
    "\n",
    "### 4. Start (self-supervised) Training\n",
    "```bash \n",
    "TARGET_DATASET=4\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train $TARGET_DATASET 3d_fullres 0 & # train on GPU 0\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train $TARGET_DATASET 3d_fullres 1 & # train on GPU 1\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train $TARGET_DATASET 3d_fullres 2 & # train on GPU 2\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNetv2_train $TARGET_DATASET 3d_fullres 3 & # train on GPU 3\n",
    "CUDA_VISIBLE_DEVICES=4 nnUNetv2_train $TARGET_DATASET 3d_fullres 4 & # train on GPU 4\n",
    "wait\n",
    "```\n",
    "\n",
    "### 5. Transfer Plans for Fine-Tuning\n",
    "```bash \n",
    "TARGET_DATASET=5\n",
    "SOURCE_DATASET=4\n",
    "TARGET_PLANS_IDENTIFIER=nnUNetPlans_finetuning\n",
    "SOURCE_PLANS_IDENTIFIER=nnUNetPlans\n",
    "\n",
    "nnUNetv2_move_plans_between_datasets -t $TARGET_DATASET -s $SOURCE_DATASET -tp $TARGET_PLANS_IDENTIFIER -sp $SOURCE_PLANS_IDENTIFIER\n",
    "nnUNetv2_preprocess -d $TARGET_DATASET -plans_name $TARGET_PLANS_IDENTIFIER\n",
    "```\n",
    "\n",
    "### 6. Start (fine-tuning) Training\n",
    "```bash \n",
    "# Use a new virtual environment in which nnUnet uses a lowered learning rate\n",
    "mamba activate nnUNet_finetuning\n",
    "\n",
    "TARGET_DATASET=5\n",
    "PATH_TO_CHECKPOINT=\"/$nnUnet_root/nnUNet_results/Dataset004_allSections/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_0/checkpoint_best.pth\"\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train $TARGET_DATASET 3d_fullres 0 -pretrained_weights $PATH_TO_CHECKPOINT & # train on GPU 0\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train $TARGET_DATASET 3d_fullres 1 -pretrained_weights $PATH_TO_CHECKPOINT & # train on GPU 1\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train $TARGET_DATASET 3d_fullres 2 -pretrained_weights $PATH_TO_CHECKPOINT & # train on GPU 2\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNetv2_train $TARGET_DATASET 3d_fullres 3 -pretrained_weights $PATH_TO_CHECKPOINT & # train on GPU 3\n",
    "CUDA_VISIBLE_DEVICES=4 nnUNetv2_train $TARGET_DATASET 3d_fullres 4 -pretrained_weights $PATH_TO_CHECKPOINT & # train on GPU 4\n",
    "wait\n",
    "mamba deactivate\n",
    "```\n",
    "\n",
    "### 7. Inference\n",
    "```bash \n",
    "INPUT_FOLDER=\"$nnUnet_root/data/images\"\n",
    "OUTPUT_FOLDER=\"$nnUnet_root/data/preds_ft\"\n",
    "DATASET_NAME_OR_ID=5\n",
    "CONFIGURATION=\"3d_fullres\"\n",
    "\n",
    "nnUNetv2_predict -i $INPUT_FOLDER -o $OUTPUT_FOLDER -d $DATASET_NAME_OR_ID -c $CONFIGURATION\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
