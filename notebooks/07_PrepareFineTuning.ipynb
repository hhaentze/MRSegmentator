{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f64e033-7e90-4cec-a71b-e64fad315cd9",
   "metadata": {},
   "source": [
    "# Prepare Fine Tuning\n",
    "Fine tune the segmentaion model on Lina's annotations.\n",
    "\n",
    "We have annotations for 31 subjects, three sections each. I split this in:\n",
    "- train set: 25 subjects\n",
    "- validation set: 6 subjects\n",
    "\n",
    "For each section we have four different dixon sequences. In total this is:\n",
    "- train set: 300 scans\n",
    "- validation set: 72 scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d2b55b4-17a4-43d1-ba2b-8a3fb39c64b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "# private libraries\n",
    "import sys\n",
    "\n",
    "if \"../scripts\" not in sys.path:\n",
    "    sys.path.insert(1, \"../scripts\")\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "747c258a-adff-4c22-9287-562db3c33898",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 372 scans for a total of 31 subjects.\n"
     ]
    }
   ],
   "source": [
    "# Look for annotated scans\n",
    "annotations = [f.name for f in os.scandir(config.ukbb + \"annotations\") if f.name[-7:] == \".nii.gz\"]\n",
    "patients = set([int(f.split(\"_\")[0]) for f in annotations])\n",
    "\n",
    "# Load manifest\n",
    "data = pd.read_csv(config.ukbb + \"manifest.csv\")\n",
    "data = data.loc[data[\"eid\"].apply(lambda x: x in patients)]\n",
    "data = data.loc[data[\"section\"].apply(lambda x: x in [1, 2, 3])]\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Map water only labels to other sequence types\n",
    "data[\"label\"] = data[\"image\"].apply(lambda x: x.replace(\"/\", \"_\"))\n",
    "data[\"label\"] = data[\"label\"].apply(lambda x: x.replace(\"in\", \"W\"))\n",
    "data[\"label\"] = data[\"label\"].apply(lambda x: x.replace(\"opp\", \"W\"))\n",
    "data[\"label\"] = data[\"label\"].apply(lambda x: x.replace(\"F\", \"W\"))\n",
    "\n",
    "print(f\"Found {len(data)} scans for a total of {len(patients)} subjects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3c5a4b-e2d5-4107-933f-e61ddc03c997",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Put 25 subjects in the train set and 6 subjects in the validation set.\n"
     ]
    }
   ],
   "source": [
    "# Train and validation split\n",
    "random.seed(42)\n",
    "valid_patients = set(random.sample(list(patients), 6))\n",
    "train_patients = patients.difference(valid_patients)\n",
    "print(\n",
    "    f\"Put {len(train_patients)} subjects in the train set and {len(valid_patients)} subjects in the validation set.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aa6e3c3-4f0c-4838-9972-045981f842e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save as csv\n",
    "train_set = data.loc[data[\"eid\"].apply(lambda x: x in train_patients)].reset_index(drop=True)\n",
    "valid_set = data.loc[data[\"eid\"].apply(lambda x: x in valid_patients)].reset_index(drop=True)\n",
    "\n",
    "valid_set.to_csv(config.ukbb + \"valid_finetuning.csv\", index=False)\n",
    "train_set.sample(random_state=13, frac=1).to_csv(config.ukbb + \"train_finetuning.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
